{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXoQ4tmbz+mPbTaGT0kCCl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajan5639/Machine_learning/blob/main/ML_ensemble_Assignment_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3isVc85N90oZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "1. Can we use Bagging for regression problems?\n",
        "Yes, Bagging can be used for regression problems. The Bagging Regressor is an ensemble learning method that applies bootstrap aggregation to regression models.\n",
        " It works by training multiple instances of a base regression model on different subsets of the training data (sampled with replacement) and then averaging their predictions.\n",
        "  This reduces variance and helps in avoiding overfitting.\n",
        "\n",
        "A popular example of bagging in regression is the Random Forest Regressor, which consists of multiple decision trees whose outputs are averaged to make a final prediction.\n",
        "\n",
        "Bagging works well for high-variance models like decision trees and helps improve their stability and accuracy by reducing the impact of noise in the dataset.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "QglyWdJP90mJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "2. What is the difference between multiple model training and single model training?\n",
        "Single model training involves training a single predictive model on the given dataset, whereas multiple model training (ensemble learning) involves training multiple models and combining their predictions to improve accuracy and robustness.\n",
        "\n",
        "Single Model Training:\n",
        "Uses only one algorithm.\n",
        "More prone to overfitting or underfitting.\n",
        "Performance depends entirely on a single model’s capability.\n",
        "Multiple Model Training (Ensemble Methods):\n",
        "Uses multiple models to improve performance.\n",
        "Reduces bias and variance.\n",
        "More robust and generalizes well to unseen data.\n",
        "Examples include Bagging, Boosting, and Stacking.\n",
        "By combining multiple models, ensemble methods can outperform individual models, especially in complex datasets where a single model may struggle to generalize well.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "j8mKPS1490jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "\n",
        "3. Explain the concept of feature randomness in Random Forest.\n",
        "Feature randomness in Random Forest refers to how the model selects a random subset of features at each split while constructing individual decision trees. This randomness ensures diversity among the trees, making the ensemble more robust.\n",
        "\n",
        "How Feature Randomness Works:\n",
        "In standard decision trees, the best feature is chosen at every split based on a criterion like Gini impurity or information gain.\n",
        "In Random Forest, instead of considering all features, a random subset of features is selected at each node, and the best feature from this subset is chosen for splitting.\n",
        "This randomness decorrelates the trees, reducing overfitting and improving generalization.\n",
        "Benefits of Feature Randomness:\n",
        "Prevents certain dominant features from overpowering the model.\n",
        "Ensures that different trees learn different aspects of the data.\n",
        "Helps improve prediction accuracy, especially on unseen data.\n",
        "By introducing both bootstrapped data samples and feature randomness, Random Forest becomes a powerful and stable ensemble method.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "SSRcLOHZ90hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        ". What is OOB (Out-of-Bag) Score?\n",
        "The Out-of-Bag (OOB) Score is an internal performance evaluation metric used in Random Forest to estimate its accuracy without needing a separate validation set. It is based on the idea of bootstrap sampling, where each decision tree in the forest is trained on a randomly selected subset of the training data.\n",
        "\n",
        "How OOB Score Works:\n",
        "Each tree in the Random Forest is trained on a bootstrap sample (randomly drawn with replacement).\n",
        "About 37% of the training data is left out of each tree’s training process. These left-out samples are called out-of-bag samples.\n",
        "After training, each tree makes predictions on its corresponding OOB samples.\n",
        "The final OOB score is calculated as the average prediction accuracy across all these OOB samples.\n",
        "Advantages of OOB Score:\n",
        "Eliminates the need for a separate validation set, making it useful when data is limited.\n",
        "Provides an unbiased estimate of the model’s performance.\n",
        "Helps in detecting overfitting, as OOB error tends to be higher if the model is too complex.\n",
        "OOB score is an efficient way to assess the generalization ability of a Random Forest model without using cross-validation.\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "gfQgLtU790fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "5. How can you measure the importance of features in a Random Forest model?\n",
        "Feature importance in a Random Forest model helps determine which features have the most influence on predictions. Random Forest provides two main techniques to measure feature importance:\n",
        "\n",
        "1. Mean Decrease in Impurity (MDI) – Gini Importance\n",
        "Each decision tree in the Random Forest splits nodes based on a feature that provides the highest information gain or Gini impurity reduction.\n",
        "The importance of a feature is calculated as the average impurity reduction across all trees where the feature was used for splitting.\n",
        "The more a feature reduces impurity, the higher its importance.\n",
        "2. Mean Decrease in Accuracy (MDA) – Permutation Importance\n",
        "This method measures how much the model’s accuracy drops when a particular feature’s values are randomly shuffled (disrupted).\n",
        "If shuffling a feature significantly reduces model accuracy, it means the feature was important for predictions.\n",
        "If shuffling has little to no effect, the feature is considered less important\n",
        "'''"
      ],
      "metadata": {
        "id": "yMNAjMXx90dJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6MWZRL5w90ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "6. Explain the working principle of a Bagging Classifier.\n",
        "A Bagging Classifier (Bootstrap Aggregating Classifier) is an ensemble learning method that improves model stability and accuracy by training multiple models on different random subsets of the training data and then combining their predictions.\n",
        "\n",
        "How Bagging Classifier Works:\n",
        "Bootstrap Sampling:\n",
        "\n",
        "Multiple training sets are created by randomly selecting samples with replacement from the original dataset.\n",
        "Each new dataset is called a bootstrap sample and has the same size as the original dataset.\n",
        "Model Training:\n",
        "\n",
        "A separate model (usually a Decision Tree) is trained on each bootstrap sample.\n",
        "Since each model sees a slightly different dataset, they learn different patterns.\n",
        "Prediction Aggregation:\n",
        "\n",
        "For classification tasks, predictions from all models are combined using majority voting (the most common predicted class is chosen).\n",
        "For regression tasks, predictions are averaged to get the final output.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "bKNxAu-s90Yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. How do you evaluate a Bagging Classifier's performance?\n",
        "# Evaluating the performance of a Bagging Classifier is essential to ensure that it improves accuracy, reduces variance, and generalizes well to new data. Several methods can be used to assess its effectiveness:\n",
        "\n",
        "# 1. Accuracy Score (for Classification) and R² Score (for Regression)\n",
        "# Accuracy is a simple metric for classification tasks, measuring how many predictions are correct.\n",
        "# The R² score (coefficient of determination) is used for regression models to measure how well predictions match actual values.\n",
        "# Example in Python:\n",
        "\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create Bagging Classifier\n",
        "bagging = BaggingClassifier(DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
        "bagging.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = bagging.predict(X_test)\n",
        "\n",
        "# Evaluate Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Bagging Classifier Accuracy:\", accuracy)\n",
        "# 2. Confusion Matrix and Classification Report (for Classification Tasks)\n",
        "# The confusion matrix helps analyze how many predictions were correct or incorrect for each class.\n",
        "# The classification report includes precision, recall, and F1-score for a deeper understanding of performance.\n",
        "# Example in Python:\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Generate confusion matrix and report\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "# 3. Cross-Validation for Stability\n",
        "# K-Fold Cross-Validation splits the data into k subsets and evaluates the model multiple times to check consistency.\n",
        "# This helps measure if the model performs well on different data splits.\n",
        "# Example in Python:\n",
        "\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Perform 5-fold cross-validation\n",
        "cv_scores = cross_val_score(bagging, X, y, cv=5, scoring='accuracy')\n",
        "print(\"Cross-Validation Accuracy Scores:\", cv_scores)\n",
        "print(\"Mean Accuracy:\", cv_scores.mean())\n",
        "# 4. Out-of-Bag (OOB) Score (Specific to Bagging)\n",
        "# Since bagging uses bootstrap sampling, around 37% of training data is left out from each model (Out-of-Bag data).\n",
        "# OOB score is an internal validation metric to estimate performance without a separate validation set.\n",
        "# Enable OOB Score in BaggingClassifier:\n",
        "\n",
        "\n",
        "bagging = BaggingClassifier(DecisionTreeClassifier(), n_estimators=50, oob_score=True, random_state=42)\n",
        "bagging.fit(X_train, y_train)\n",
        "print(\"OOB Score:\", bagging.oob_score_)\n"
      ],
      "metadata": {
        "id": "JRHTyJWC90WX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "8. How does a Bagging Regressor work?\n",
        "A Bagging Regressor is an ensemble learning technique that improves the performance of regression models by reducing variance and increasing stability. It works by training multiple instances of the same regression model on different bootstrap samples of the dataset and then aggregating their predictions.\n",
        "\n",
        "Working Principle of Bagging Regressor\n",
        "Bootstrap Sampling:\n",
        "\n",
        "Multiple subsets of the training data are created using bootstrap sampling (sampling with replacement).\n",
        "Each subset is of the same size as the original dataset, but some data points may appear multiple times while others may be missing.\n",
        "Model Training:\n",
        "\n",
        "A base regression model (like Decision Tree Regressor, Linear Regression, or SVR) is trained on each bootstrap sample.\n",
        "Each model learns slightly different patterns due to the varying training data.\n",
        "Prediction Aggregation:\n",
        "\n",
        "Once trained, all the models predict values for the test data.\n",
        "The final prediction is obtained by averaging the predictions from all models.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "When to Use Bagging Regressor?\n",
        "When you have a high-variance model like Decision Trees, bagging helps smooth predictions.\n",
        "When the dataset is noisy or has outliers, bagging reduces their impact.\n",
        "When you need a more stable and generalized regression model.\n",
        "Key Takeaways\n",
        "Bagging Regressor is an ensemble technique that aggregates multiple regressors to improve performance.\n",
        "It uses bootstrap sampling and averaging to make predictions more reliable.\n",
        "Works well with Decision Trees, Linear Regression, and other regressors to reduce variance.\n",
        "Performance is measured using MSE (Mean Squared Error), RMSE, or R² Score.\n",
        "Bagging Regressor is a powerful technique when dealing with complex regression problems where reducing variance is essential.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "es3YA08F90UB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "9. What are the advantages and disadvantages of Bagging?\n",
        "Bagging (Bootstrap Aggregating) is a powerful ensemble learning technique used to improve the performance of machine learning models by reducing variance and increasing stability. However, it has both advantages and disadvantages that should be considered before implementation.\n",
        "\n",
        "Advantages of Bagging\n",
        "1. Reduces Overfitting (Variance Reduction)\n",
        "Since bagging trains multiple models on different bootstrap samples and aggregates their predictions, it reduces variance and prevents overfitting.\n",
        "Works well for high-variance models like Decision Trees.\n",
        "2. Improves Model Stability & Accuracy\n",
        "Bagging makes models more stable by averaging predictions from multiple models, which improves generalization to new data.\n",
        "It often increases accuracy compared to a single model.\n",
        "3. Handles Noisy Data Better\n",
        "Since each model is trained on different random subsets, individual outliers or noise have less impact on the final prediction.\n",
        "This makes bagging robust to noisy datasets.\n",
        "4. Works Well with Complex Models\n",
        "Bagging is particularly effective with non-linear models like Decision Trees, Neural Networks, and k-NN, which tend to have high variance.\n",
        "5. Can Use Out-of-Bag (OOB) Score for Validation\n",
        "Bagging allows an internal validation metric (OOB Score) using the unused training data, reducing the need for a separate validation set.\n",
        "Disadvantages of Bagging\n",
        "1. Increased Computational Cost\n",
        "Bagging requires training multiple models instead of just one, making it computationally expensive.\n",
        "It may not be suitable for real-time applications where speed is critical.\n",
        "2. Does Not Reduce Bias\n",
        "Bagging mainly reduces variance but does not lower bias.\n",
        "If the base model is too simple (e.g., linear regression on non-linear data), bagging will not improve its accuracy significantly.\n",
        "3. Requires More Storage and Memory\n",
        "Since bagging trains multiple models, it requires more memory and storage than a single model.\n",
        "This can be a challenge when dealing with large datasets.\n",
        "4. Not Always Useful for Low-Variance Models\n",
        "Models like Linear Regression or Naïve Bayes already have low variance; applying bagging may not significantly improve performance.\n",
        "When to Use Bagging?\n",
        "When using high-variance models like Decision Trees to reduce overfitting.\n",
        "When dealing with noisy datasets where stable predictions are needed.\n",
        "When a slightly higher computational cost is acceptable for improved accuracy.\n",
        "When an internal validation metric (OOB Score) is needed without separate test data.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "r-Qpddwo90R7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "10. Compare Bagging and Boosting.\n",
        "Bagging and Boosting are both ensemble learning techniques that improve the performance of machine learning models by combining multiple weak learners. However, they work differently in terms of training models, handling errors, and reducing bias or variance. Below is a detailed comparison of both methods.\n",
        "\n",
        "1. Definition\n",
        "Bagging (Bootstrap Aggregating):\n",
        "\n",
        "Bagging involves training multiple models independently in parallel using different random subsets of the data (bootstrap sampling).\n",
        "The final prediction is made by averaging the outputs (for regression) or majority voting (for classification).\n",
        "Example: Random Forest is a popular bagging algorithm.\n",
        "Boosting:\n",
        "\n",
        "Boosting trains models sequentially, where each new model focuses on correcting the errors made by the previous models.\n",
        "The models are weighted based on their accuracy, and their predictions are combined to improve the final result.\n",
        "Example: AdaBoost, Gradient Boosting, XGBoost, LightGBM, and CatBoost.\n",
        "2. Working Mechanism\n",
        "Bagging (Parallel Learning)\n",
        "Each model is trained independently on randomly sampled data.\n",
        "Predictions from all models are combined by majority voting (classification) or averaging (regression).\n",
        "Reduces variance and prevents overfitting.\n",
        "Boosting (Sequential Learning)\n",
        "Models are trained one after another, and each model corrects the mistakes made by the previous one.\n",
        "Assigns higher weight to misclassified instances to focus on harder examples.\n",
        "Reduces bias and improves accuracy, but can overfit if not tuned properly.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "Y7f6kjXD90Pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "11. Explain the concept of entropy in the context of Decision Trees.\n",
        "1. Definition of Entropy\n",
        "Entropy is a fundamental concept in information theory and is used in decision trees to measure the impurity or randomness of a dataset.\n",
        "\n",
        "It helps in determining how well a given feature separates the data into different classes.\n",
        "\n",
        "In simple terms, entropy quantifies the uncertainty in a dataset—a high entropy means the dataset is highly impure (contains mixed classes), whereas a low entropy means the dataset is pure (mostly belongs to one class).\n",
        "\n",
        "2. Understanding Entropy with Examples\n",
        "Case 1: Pure Dataset (Entropy = 0)\n",
        "\n",
        "Suppose we have a dataset where all instances belong to the same class (e.g., all \"Yes\").\n",
        "Since there is no uncertainty, entropy is 0 (lowest possible value).\n",
        "\n",
        "\n",
        "\n",
        "3. Entropy in Decision Trees\n",
        "Decision Trees use entropy to select the best feature for splitting the data at each node.\n",
        "\n",
        "Entropy Before Split: Measures how impure the dataset is before splitting.\n",
        "Entropy After Split: Measures the weighted sum of the entropy of child nodes after splitting.\n",
        "Information Gain:\n",
        "The reduction in entropy after splitting is called Information Gain.\n",
        "The feature with the highest information gain is selected for splitting the node.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "JoUgjxWv90Ne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JemrY4gW90K4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "13. Explain the concept of Information Gain in Decision Trees.\n",
        "1. What is Information Gain?\n",
        "Information Gain (IG) is a measure used in Decision Trees to determine the best feature to split a dataset.\n",
        " It quantifies how much uncertainty (entropy) is reduced after a split. The feature with the highest Information Gain is chosen for splitting because it creates the purest child nodes.\n",
        "\n",
        "Entropy (Parent): Measures the impurity of the original dataset.\n",
        "\n",
        "Entropy (Child): Measures impurity after splitting.\n",
        "\n",
        "|Child| / |Parent|: Weight of each child node in the total dataset.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "BMDl2tKm90Im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "14. Explain the concept of Pruning in Decision Trees.\n",
        "1. What is Pruning in Decision Trees?\n",
        "Pruning is a technique used to reduce the size of a Decision Tree by removing branches that provide little or no predictive power. It helps to prevent overfitting by simplifying the tree structure while maintaining accuracy.\n",
        "\n",
        "Pruning can be applied during tree construction (pre-pruning) or after the tree has been fully grown (post-pruning).\n",
        "\n",
        "2. Why is Pruning Necessary?\n",
        "When a Decision Tree grows too deep, it captures noise in the training data, leading to overfitting. Overfitting results in a tree that:\n",
        "\n",
        "Fits the training data perfectly but performs poorly on unseen data.\n",
        "Has unnecessary branches that add complexity.\n",
        "Pruning helps by:\n",
        "\n",
        "Reducing model complexity.\n",
        "Improving generalization to new data.\n",
        "Avoiding data-specific splits that do not contribute to better predictions.\n",
        "3. Types of Pruning\n",
        "A. Pre-Pruning (Early Stopping)\n",
        "Also known as \"early stopping,\" pre-pruning stops the tree from growing before it becomes too complex.\n",
        "It uses conditions like:\n",
        "Maximum depth limit → Stop growing the tree beyond a certain depth.\n",
        "Minimum samples per split → Require a minimum number of samples to split a node.\n",
        "Minimum impurity decrease → Stop splitting if the reduction in impurity (Gini/Entropy) is too small.\n",
        "Pros:\n",
        "Prevents unnecessary complexity early.\n",
        "Saves computation time.\n",
        "Cons:\n",
        "Risk of stopping too soon, missing useful splits.\n",
        "B. Post-Pruning (Pruning After Tree Construction)\n",
        "The tree is first grown fully, then unnecessary branches are pruned based on their performance on validation data.\n",
        "Two common post-pruning techniques:\n",
        "1. Cost Complexity Pruning (CCP) (Used in CART Algorithm)\n",
        "\n",
        "Introduces a penalty for tree complexity by adding a cost term.\n",
        "The tree is pruned by balancing model accuracy and tree complexity.\n",
        "2. Reduced Error Pruning\n",
        "\n",
        "The tree is pruned from bottom to top by removing nodes that do not reduce validation error.\n",
        "\n",
        "If removing a subtree does not harm accuracy, it is deleted.\n",
        "\n",
        "Pros:\n",
        "\n",
        "More reliable than pre-pruning.\n",
        "Reduces overfitting without missing important splits.\n",
        "Cons:\n",
        "\n",
        "Requires additional validation data.\n",
        "Computationally expensive.\n",
        "4. Example of Pruning in Decision Trees\n",
        "Before Pruning (Overfitted Tree)\n",
        "yaml\n",
        "Copy\n",
        "Edit\n",
        "                Weather\n",
        "               /       \\\n",
        "           Sunny       Rainy\n",
        "          /    \\        /    \\\n",
        "      Hot    Cold     Yes     No\n",
        "     /   \\   /   \\\n",
        "    Yes   No  Yes   No\n",
        "The tree has too many splits, even for small variations in data.\n",
        "After Pruning (Simplified Tree)\n",
        "markdown\n",
        "Copy\n",
        "Edit\n",
        "                Weather\n",
        "               /       \\\n",
        "           Sunny       Rainy\n",
        "              |         |\n",
        "            No       Yes\n",
        "The unnecessary splits were removed, making the tree simpler and generalizable.\n",
        "\n",
        "\n",
        "'''\n"
      ],
      "metadata": {
        "id": "UU7HqjnF90GQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "15 15. Explain Gini Impurity and Entropy in Decision Trees.\n",
        "1. What are Gini Impurity and Entropy?\n",
        "Both Gini Impurity and Entropy are measures of impurity used in Decision Trees to determine how good a split is. They help in selecting the best feature by measuring how mixed the class labels are at a node.\n",
        "\n",
        "Gini Impurity measures the probability of misclassification at a node.\n",
        "Entropy measures the uncertainty or disorder in the dataset.\n",
        "The goal of a Decision Tree is to reduce impurity at each split, leading to purer child nodes.\n",
        "\n",
        "\n",
        "\n",
        " Gini Impurity\n",
        "Gini Impurity measures the likelihood of incorrectly classifying a randomly chosen element. A lower Gini score indicates a purer node.\n",
        "\n",
        "\n",
        " Key Takeaways\n",
        "Gini Impurity and Entropy are used to measure impurity in Decision Trees.\n",
        "Gini is computationally faster (preferred in large datasets).\n",
        "Entropy provides better interpretability but is slower due to logarithms.\n",
        "Both aim to create the purest possible nodes at each split.\n",
        "CART uses Gini Impurity, while ID3, C4.5, and C5.0 use Entropy.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "LyLGhQNM90Dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "16. Explain Information Gain in Decision Trees.\n",
        "1. What is Information Gain?\n",
        "Information Gain (IG) is a metric used in Decision Trees to determine the best feature for splitting data at each step.\n",
        "It measures the reduction in entropy (uncertainty) when a dataset is split based on a particular feature.\n",
        "\n",
        "Higher Information Gain → Better split (more reduction in uncertainty).\n",
        "Lower Information Gain → Poor split (less reduction in uncertainty).\n",
        "Decision Trees use Information Gain to decide which feature to split on at each node. The feature with the highest IG is chosen.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Entropy(Parent) → Entropy before splitting.\n",
        "Subset → The child nodes after splitting.\n",
        "|Subset| / |Parent| → The proportion of samples in each subset.\n",
        "Entropy(Subset) → Entropy of each child node.\n",
        "The goal is to maximize IG to create pure child nodes (less entropy).\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "MCRkGF1h90Ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "17. Explain Gini Impurity in Decision Trees.\n",
        "1. What is Gini Impurity?\n",
        "\n",
        "Gini Impurity is a measure of how impure (or mixed) a dataset is.\n",
        "It is used in Decision Trees to decide how to split the data at each step.\n",
        "The lower the Gini Impurity, the purer the dataset.\n",
        "\n",
        "If a node contains only one class (pure), Gini = 0\n",
        "If a node contains mixed classes, Gini > 0\n",
        "The goal of a Decision Tree is to split in a way that minimizes Gini Impurity.\n",
        "\n",
        "\n",
        "Key Takeaways\n",
        "Gini Impurity measures how impure a dataset is.\n",
        "Lower Gini means a better split (more purity).\n",
        "Gini is used in Decision Trees to choose the best feature for splitting.\n",
        "It is faster than entropy but slightly less precise.\n",
        "'''\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8gRqTr4K9z_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "18. Explain Pruning in Decision Trees.\n",
        "1. What is Pruning?\n",
        "Pruning is a technique used in Decision Trees to reduce the tree's complexity by removing unnecessary branches. This helps prevent overfitting, making the model more generalizable to new data.\n",
        "\n",
        "There are two types of pruning:\n",
        "\n",
        "Pre-Pruning (Early Stopping) → Stops the tree from growing too deep.\n",
        "Post-Pruning (Pruning After Training) → Removes branches after the tree is fully grown.\n",
        "2. Why is Pruning Necessary?\n",
        "Decision Trees can easily overfit, especially with noisy data.\n",
        "A deep tree memorizes training data, but performs poorly on unseen data.\n",
        "Pruning simplifies the model, improving accuracy on test data.\n",
        "3. Types of Pruning\n",
        "A. Pre-Pruning (Early Stopping)\n",
        "Stops the tree from growing beyond a certain depth.\n",
        "Prevents overfitting by applying constraints during training.\n",
        "Techniques Used:\n",
        "\n",
        "Maximum Depth (max_depth) → Limits the depth of the tree.\n",
        "Minimum Samples Split (min_samples_split) → Ensures a minimum number of samples before splitting.\n",
        "Minimum Samples Leaf (min_samples_leaf) → Ensures a minimum number of samples in each leaf node.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "B. Post-Pruning (Reduced Error Pruning)\n",
        "The tree is first grown completely, then unnecessary branches are removed.\n",
        "Pruning starts from leaf nodes and removes nodes that do not improve accuracy.\n",
        "Steps for Post-Pruning:\n",
        "\n",
        "Grow the full tree (allow overfitting).\n",
        "Evaluate the accuracy of subtrees.\n",
        "Remove nodes that do not improve validation accuracy.\n",
        "Repeat until no further improvement is possible.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "GjYIZhEo9z85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "19. Explain the Bias-Variance Tradeoff in Machine Learning.\n",
        "1. What is the Bias-Variance Tradeoff?\n",
        "The Bias-Variance Tradeoff is a fundamental concept in machine learning that describes the balance between two sources of error in a model:\n",
        "\n",
        "Bias (Underfitting) → Error due to incorrect assumptions in the model.\n",
        "Variance (Overfitting) → Error due to high sensitivity to training data.\n",
        "A good machine learning model should balance bias and variance to achieve low total error on new data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The Bias-Variance Tradeoff is a fundamental concept in machine learning that describes the balance between two sources of error in a model:\n",
        "\n",
        "Bias (Underfitting) → Error due to incorrect assumptions in the model.\n",
        "Variance (Overfitting) → Error due to high sensitivity to training data.\n",
        "A good machine learning model should balance bias and variance to achieve low total error on new data.\n",
        "\n",
        "'''\n"
      ],
      "metadata": {
        "id": "yX_o0FZu9z6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "20. What is Cross-Validation in Machine Learning? Explain Different Types of Cross-Validation.\n",
        "1. What is Cross-Validation?\n",
        "Cross-validation is a model evaluation technique used in machine learning to assess the performance and generalization ability of a model. It helps ensure that the model is not overfitting or underfitting by training and testing on different subsets of the dataset multiple times.\n",
        "\n",
        "Instead of using a single train-test split, cross-validation splits the dataset into multiple subsets, trains the model on some parts, and validates it on others. The results are then averaged to get a more reliable estimate of the model's performance.\n",
        "\n",
        "2. Why is Cross-Validation Important?\n",
        " Prevents Overfitting: Ensures that the model is not memorizing the training data.\n",
        " Better Performance Estimate: Provides a more accurate measure of model accuracy.\n",
        " Efficient Use of Data: Uses all data for both training and testing, improving generalization.\n",
        "\n",
        "3. Different Types of Cross-Validation\n",
        "A. Holdout Method (Simple Train-Test Split)\n",
        "The dataset is divided into two parts:\n",
        "Training Set (e.g., 80%) → Used to train the model.\n",
        "Testing Set (e.g., 20%) → Used to evaluate performance.\n",
        "This is the simplest form of validation but may not work well for small datasets.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "fp7K9XQS9z38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zBoJ4CZO9z1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#21. Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy.\n",
        "\n",
        "#21. Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy.\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generate a sample dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Bagging Classifier using Decision Trees\n",
        "# The parameter name has changed to 'estimator' in newer versions\n",
        "bagging_clf = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "bagging_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = bagging_clf.predict(X_test)\n",
        "\n",
        "# Print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Bagging Classifier Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rsin8-l9zzN",
        "outputId": "0a30e614-cfe0-4ae4-841e-8fd13d976267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier Accuracy: 0.885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#22. Train a Bagging Regressor using Decision Trees and evaluate using Mean Squared Error (MSE).\n",
        "\n",
        "#22. Train a Bagging Regressor using Decision Trees and evaluate using Mean Squared Error (MSE).\n",
        "\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Generate a sample regression dataset\n",
        "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=42)\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Bagging Regressor using Decision Trees\n",
        "# Replace 'base_estimator' with 'estimator'\n",
        "bagging_reg = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=10, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "bagging_reg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = bagging_reg.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Bagging Regressor Mean Squared Error:\", mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cR-wd7D99zwv",
        "outputId": "d172f4d2-42d9-4058-ebe7-38d1ccda9916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Regressor Mean Squared Error: 7484.147276569565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#23. Train a Random Forest Classifier on the Breast Cancer dataset and print feature importance scores.\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importance scores\n",
        "feature_importance = rf_classifier.feature_importances_\n",
        "\n",
        "# Create a DataFrame to display feature importance\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': data.feature_names,\n",
        "    'Importance': feature_importance\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Print feature importance scores\n",
        "print(\"Feature Importance Scores:\")\n",
        "print(feature_importance_df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtIJmAmj9zub",
        "outputId": "d383b2bd-7044-43bd-b163-63f3702f633a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importance Scores:\n",
            "                    Feature  Importance\n",
            "23               worst area    0.153892\n",
            "27     worst concave points    0.144663\n",
            "7       mean concave points    0.106210\n",
            "20             worst radius    0.077987\n",
            "6            mean concavity    0.068001\n",
            "22          worst perimeter    0.067115\n",
            "2            mean perimeter    0.053270\n",
            "0               mean radius    0.048703\n",
            "3                 mean area    0.047555\n",
            "26          worst concavity    0.031802\n",
            "13               area error    0.022407\n",
            "21            worst texture    0.021749\n",
            "25        worst compactness    0.020266\n",
            "10             radius error    0.020139\n",
            "5          mean compactness    0.013944\n",
            "1              mean texture    0.013591\n",
            "12          perimeter error    0.011303\n",
            "24         worst smoothness    0.010644\n",
            "28           worst symmetry    0.010120\n",
            "16          concavity error    0.009386\n",
            "4           mean smoothness    0.007285\n",
            "19  fractal dimension error    0.005321\n",
            "15        compactness error    0.005253\n",
            "29  worst fractal dimension    0.005210\n",
            "11            texture error    0.004724\n",
            "14         smoothness error    0.004271\n",
            "18           symmetry error    0.004018\n",
            "9    mean fractal dimension    0.003886\n",
            "8             mean symmetry    0.003770\n",
            "17     concave points error    0.003513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#24. Train a Random Forest Regressor and compare its performance with a single Decision Tree.\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the California Housing dataset\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Regressor\n",
        "dt_regressor = DecisionTreeRegressor(random_state=42)\n",
        "dt_regressor.fit(X_train, y_train)\n",
        "dt_predictions = dt_regressor.predict(X_test)\n",
        "\n",
        "# Train a Random Forest Regressor\n",
        "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_regressor.fit(X_train, y_train)\n",
        "rf_predictions = rf_regressor.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Error (MSE) for both models\n",
        "dt_mse = mean_squared_error(y_test, dt_predictions)\n",
        "rf_mse = mean_squared_error(y_test, rf_predictions)\n",
        "\n",
        "# Print the results\n",
        "print(\"Decision Tree Regressor MSE:\", dt_mse)\n",
        "print(\"Random Forest Regressor MSE:\", rf_mse)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxRTn6tJ9zsB",
        "outputId": "b586a96a-dc95-4f81-a983-5975e03cce08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Regressor MSE: 0.495235205629094\n",
            "Random Forest Regressor MSE: 0.2553684927247781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# q25\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split into training and testing sets (though not needed for OOB score)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Random Forest Classifier with OOB Score enabled\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Print the Out-of-Bag Score\n",
        "print(\"Out-of-Bag (OOB) Score:\", rf_classifier.oob_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WgXYI5sWnJV",
        "outputId": "693c474f-7606-48e6-e3ce-70536f407f4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Out-of-Bag (OOB) Score: 0.9560439560439561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#26. Train a Bagging Classifier using SVM as a base estimator and print accuracy.\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the base estimator (Support Vector Classifier)\n",
        "svm_base = SVC(kernel='rbf', probability=True, random_state=42)\n",
        "\n",
        "# Train a Bagging Classifier using SVM as the base estimator\n",
        "# Replace 'base_estimator' with 'estimator'\n",
        "bagging_classifier = BaggingClassifier(estimator=svm_base, n_estimators=10, random_state=42)\n",
        "bagging_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = bagging_classifier.predict(X_test)\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Bagging Classifier Accuracy using SVM as base estimator:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgIfqN0GWyA4",
        "outputId": "a14a3ff3-0b69-4c35-edd1-2047c4633e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier Accuracy using SVM as base estimator: 0.9473684210526315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#27. Train a Random Forest Classifier with different numbers of trees and compare accuracy.\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# List of different numbers of trees to test\n",
        "n_estimators_list = [10, 50, 100, 200]\n",
        "\n",
        "# Dictionary to store accuracy scores\n",
        "accuracy_scores = {}\n",
        "\n",
        "# Train Random Forest with different numbers of trees\n",
        "for n in n_estimators_list:\n",
        "    rf = RandomForestClassifier(n_estimators=n, random_state=42)\n",
        "    rf.fit(X_train, y_train)\n",
        "    y_pred = rf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracy_scores[n] = accuracy\n",
        "    print(f\"Random Forest with {n} trees - Accuracy: {accuracy:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1SshIZWW-mT",
        "outputId": "5e0dd832-bc94-47b6-a5c7-98dac0d3b443"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest with 10 trees - Accuracy: 0.9561\n",
            "Random Forest with 50 trees - Accuracy: 0.9649\n",
            "Random Forest with 100 trees - Accuracy: 0.9649\n",
            "Random Forest with 200 trees - Accuracy: 0.9649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#28. Train a Bagging Classifier using Logistic Regression as a base estimator and print AUC score.\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Bagging Classifier with Logistic Regression as base estimator\n",
        "# Replace 'base_estimator' with 'estimator'\n",
        "bagging_clf = BaggingClassifier(estimator=LogisticRegression(), n_estimators=50, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "bagging_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities for AUC calculation\n",
        "y_prob = bagging_clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Compute AUC score\n",
        "auc_score = roc_auc_score(y_test, y_prob)\n",
        "print(f\"AUC Score: {auc_score:.4f}\")"
      ],
      "metadata": {
        "id": "ogVQnGoEXNhp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "460f5e90-3b78-48ea-9a90-4cd42dab0976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC Score: 0.9980\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#29. Train a Random Forest Regressor and analyze feature importance scores.\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train Random Forest Regressor\n",
        "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importance scores\n",
        "feature_importances = rf_regressor.feature_importances_\n",
        "\n",
        "# Create a DataFrame for better visualization\n",
        "feature_importance_df = pd.DataFrame({'Feature': data.feature_names, 'Importance': feature_importances})\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Print feature importance scores\n",
        "print(\"Feature Importance Scores in Random Forest Regressor:\")\n",
        "print(feature_importance_df)\n"
      ],
      "metadata": {
        "id": "XF8OvAHKXiL9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b9fa7582-638b-4ba3-d2c5-d4e188fd8d13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "\n`load_boston` has been removed from scikit-learn since version 1.2.\n\nThe Boston housing prices dataset has an ethical problem: as\ninvestigated in [1], the authors of this dataset engineered a\nnon-invertible variable \"B\" assuming that racial self-segregation had a\npositive impact on house prices [2]. Furthermore the goal of the\nresearch that led to the creation of this dataset was to study the\nimpact of air quality but it did not give adequate demonstration of the\nvalidity of this assumption.\n\nThe scikit-learn maintainers therefore strongly discourage the use of\nthis dataset unless the purpose of the code is to study and educate\nabout ethical issues in data science and machine learning.\n\nIn this special case, you can fetch the dataset from the original\nsource::\n\n    import pandas as pd\n    import numpy as np\n\n    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n    raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n    target = raw_df.values[1::2, 2]\n\nAlternative datasets include the California housing dataset and the\nAmes housing dataset. You can load the datasets as follows::\n\n    from sklearn.datasets import fetch_california_housing\n    housing = fetch_california_housing()\n\nfor the California housing dataset and::\n\n    from sklearn.datasets import fetch_openml\n    housing = fetch_openml(name=\"house_prices\", as_frame=True)\n\nfor the Ames housing dataset.\n\n[1] M Carlisle.\n\"Racist data destruction?\"\n<https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8>\n\n[2] Harrison Jr, David, and Daniel L. Rubinfeld.\n\"Hedonic housing prices and the demand for clean air.\"\nJournal of environmental economics and management 5.1 (1978): 81-102.\n<https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-3509da83be5b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_boston\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/datasets/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \"\"\"\n\u001b[1;32m    160\u001b[0m         )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: \n`load_boston` has been removed from scikit-learn since version 1.2.\n\nThe Boston housing prices dataset has an ethical problem: as\ninvestigated in [1], the authors of this dataset engineered a\nnon-invertible variable \"B\" assuming that racial self-segregation had a\npositive impact on house prices [2]. Furthermore the goal of the\nresearch that led to the creation of this dataset was to study the\nimpact of air quality but it did not give adequate demonstration of the\nvalidity of this assumption.\n\nThe scikit-learn maintainers therefore strongly discourage the use of\nthis dataset unless the purpose of the code is to study and educate\nabout ethical issues in data science and machine learning.\n\nIn this special case, you can fetch the dataset from the original\nsource::\n\n    import pandas as pd\n    import numpy as np\n\n    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n    raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n    target = raw_df.values[1::2, 2]\n\nAlternative datasets include the California housing dataset and the\nAmes housing dataset. You can load the datasets as follows::\n\n    from sklearn.datasets import fetch_california_housing\n    housing = fetch_california_housing()\n\nfor the California housing dataset and::\n\n    from sklearn.datasets import fetch_openml\n    housing = fetch_openml(name=\"house_prices\", as_frame=True)\n\nfor the Ames housing dataset.\n\n[1] M Carlisle.\n\"Racist data destruction?\"\n<https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8>\n\n[2] Harrison Jr, David, and Daniel L. Rubinfeld.\n\"Hedonic housing prices and the demand for clean air.\"\nJournal of environmental economics and management 5.1 (1978): 81-102.\n<https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>\n",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#30. Train an ensemble model using both Bagging and Random Forest and compare accuracy.\n",
        "\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Bagging Classifier with Decision Trees\n",
        "# Replace 'base_estimator' with 'estimator'\n",
        "bagging_clf = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42)\n",
        "bagging_clf.fit(X_train, y_train)\n",
        "\n",
        "# Train a Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "bagging_pred = bagging_clf.predict(X_test)\n",
        "rf_pred = rf_clf.predict(X_test)\n",
        "\n",
        "# Compute accuracy scores\n",
        "bagging_accuracy = accuracy_score(y_test, bagging_pred)\n",
        "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
        "\n",
        "# Print results\n",
        "print(f\"Bagging Classifier Accuracy: {bagging_accuracy:.4f}\")\n",
        "print(f\"Random Forest Classifier Accuracy: {rf_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "xBuvZpKvXiIZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7572152a-b6b2-49c3-9d67-aa7b0d08809f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier Accuracy: 0.9561\n",
            "Random Forest Classifier Accuracy: 0.9649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#31. Train a Voting Classifier using Logistic Regression, Decision Tree, and SVM, and compare accuracy.\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define base estimators\n",
        "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
        "decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "svm = SVC(probability=True, random_state=42)\n",
        "\n",
        "# Create Voting Classifier (hard voting)\n",
        "voting_clf = VotingClassifier(estimators=[\n",
        "    ('Logistic Regression', log_reg),\n",
        "    ('Decision Tree', decision_tree),\n",
        "    ('SVM', svm)\n",
        "], voting='hard')\n",
        "\n",
        "# Train Voting Classifier\n",
        "voting_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = voting_clf.predict(X_test)\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Voting Classifier Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "6xiE0BHTXiGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bo0YHvAJXiD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#32. Train a Stacking Classifier using Logistic Regression, Decision Tree, and SVM, and compare accuracy.\n",
        "\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define base estimators\n",
        "base_estimators = [\n",
        "    ('Logistic Regression', LogisticRegression(max_iter=1000, random_state=42)),\n",
        "    ('Decision Tree', DecisionTreeClassifier(random_state=42)),\n",
        "    ('SVM', SVC(probability=True, random_state=42))\n",
        "]\n",
        "\n",
        "# Define meta-classifier (final estimator)\n",
        "meta_classifier = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "# Create Stacking Classifier\n",
        "stacking_clf = StackingClassifier(estimators=base_estimators, final_estimator=meta_classifier)\n",
        "\n",
        "# Train the Stacking Classifier\n",
        "stacking_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = stacking_clf.predict(X_test)\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Stacking Classifier Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "mQ4a4oB5XiBW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cd17ee7-dc52-4e97-e046-ae7b07ebe329"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Classifier Accuracy: 0.9649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#33. Implement an AdaBoost Classifier using Decision Tree as a base estimator and compute accuracy.\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define base estimator (Decision Tree with max depth 1)\n",
        "base_estimator = DecisionTreeClassifier(max_depth=1, random_state=42)\n",
        "\n",
        "# Create AdaBoost Classifier\n",
        "# Replace 'base_estimator' with 'estimator'\n",
        "adaboost_clf = AdaBoostClassifier(estimator=base_estimator, n_estimators=50, random_state=42)\n",
        "\n",
        "# Train the AdaBoost Classifier\n",
        "adaboost_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = adaboost_clf.predict(X_test)\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"AdaBoost Classifier Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "q8O4szMdXh-5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55ee159b-c185-4a84-b7e4-488fd9440e39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoost Classifier Accuracy: 0.9649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 34. Implement a Gradient Boosting Classifier and compute accuracy.\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create Gradient Boosting Classifier\n",
        "gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "gb_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = gb_clf.predict(X_test)\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Gradient Boosting Classifier Accuracy: {accuracy:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Dmc9HPDVXh8i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "362009c5-2198-49a0-8c29-e37ae0761185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Classifier Accuracy: 0.9561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#35. Implement an XGBoost Classifier and compute accuracy.\n",
        "import xgboost as xgb\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create XGBoost Classifier\n",
        "xgb_clf = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "\n",
        "# Train the model\n",
        "xgb_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = xgb_clf.predict(X_test)\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"XGBoost Classifier Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "WGzS2L1vXh6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fc78b39-07cc-4cfb-a737-73c5f93335f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:18:43] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Classifier Accuracy: 0.9561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#36 #36. Implement a LightGBM Classifier and compute accuracy.\n",
        "import lightgbm as lgb\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create LightGBM Classifier\n",
        "lgb_clf = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "lgb_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = lgb_clf.predict(X_test)\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"LightGBM Classifier Accuracy: {accuracy:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "kktKQhlRXh3-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "431f7998-d100-492d-bb60-ef11b2bb6bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 286, number of negative: 169\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000637 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 4548\n",
            "[LightGBM] [Info] Number of data points in the train set: 455, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.628571 -> initscore=0.526093\n",
            "[LightGBM] [Info] Start training from score 0.526093\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "LightGBM Classifier Accuracy: 0.9649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11oOXqDRZm3x",
        "outputId": "3ebe94df-d6c1-4a4e-d62e-f30b9c523507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Collecting numpy<2.0,>=1.16.0 (from catboost)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.14.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, catboost\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "Successfully installed catboost-1.2.7 numpy-1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --force-reinstall catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TWpwHpwFZ4ro",
        "outputId": "fe99c9bc-bb3b-47de-b136-4d696a140c1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Using cached catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting graphviz (from catboost)\n",
            "  Using cached graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting matplotlib (from catboost)\n",
            "  Using cached matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting numpy<2.0,>=1.16.0 (from catboost)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting pandas>=0.24 (from catboost)\n",
            "  Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "Collecting scipy (from catboost)\n",
            "  Using cached scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting plotly (from catboost)\n",
            "  Using cached plotly-6.0.1-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting six (from catboost)\n",
            "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas>=0.24->catboost)\n",
            "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas>=0.24->catboost)\n",
            "  Using cached pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas>=0.24->catboost)\n",
            "  Using cached tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib->catboost)\n",
            "  Using cached contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib->catboost)\n",
            "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib->catboost)\n",
            "  Using cached fonttools-4.56.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (101 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib->catboost)\n",
            "  Using cached kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting packaging>=20.0 (from matplotlib->catboost)\n",
            "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pillow>=8 (from matplotlib->catboost)\n",
            "  Using cached pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib->catboost)\n",
            "  Using cached pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting narwhals>=1.15.1 (from plotly->catboost)\n",
            "  Using cached narwhals-1.31.0-py3-none-any.whl.metadata (11 kB)\n",
            "Using cached catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl (98.7 MB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "Using cached graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
            "Using cached matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "Using cached plotly-6.0.1-py3-none-any.whl (14.8 MB)\n",
            "Using cached scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
            "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Using cached contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
            "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Using cached fonttools-4.56.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "Using cached kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "Using cached narwhals-1.31.0-py3-none-any.whl (313 kB)\n",
            "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
            "Using cached pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "Using cached pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
            "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Using cached pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
            "Using cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
            "Installing collected packages: pytz, tzdata, six, pyparsing, pillow, packaging, numpy, narwhals, kiwisolver, graphviz, fonttools, cycler, scipy, python-dateutil, plotly, contourpy, pandas, matplotlib, catboost\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.1\n",
            "    Uninstalling pytz-2025.1:\n",
            "      Successfully uninstalled pytz-2025.1\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.1\n",
            "    Uninstalling tzdata-2025.1:\n",
            "      Successfully uninstalled tzdata-2025.1\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.2.1\n",
            "    Uninstalling pyparsing-3.2.1:\n",
            "      Successfully uninstalled pyparsing-3.2.1\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.1.0\n",
            "    Uninstalling pillow-11.1.0:\n",
            "      Successfully uninstalled pillow-11.1.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: narwhals\n",
            "    Found existing installation: narwhals 1.31.0\n",
            "    Uninstalling narwhals-1.31.0:\n",
            "      Successfully uninstalled narwhals-1.31.0\n",
            "  Attempting uninstall: kiwisolver\n",
            "    Found existing installation: kiwisolver 1.4.8\n",
            "    Uninstalling kiwisolver-1.4.8:\n",
            "      Successfully uninstalled kiwisolver-1.4.8\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.20.3\n",
            "    Uninstalling graphviz-0.20.3:\n",
            "      Successfully uninstalled graphviz-0.20.3\n",
            "  Attempting uninstall: fonttools\n",
            "    Found existing installation: fonttools 4.56.0\n",
            "    Uninstalling fonttools-4.56.0:\n",
            "      Successfully uninstalled fonttools-4.56.0\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.12.1\n",
            "    Uninstalling cycler-0.12.1:\n",
            "      Successfully uninstalled cycler-0.12.1\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.2\n",
            "    Uninstalling scipy-1.15.2:\n",
            "      Successfully uninstalled scipy-1.15.2\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.9.0.post0\n",
            "    Uninstalling python-dateutil-2.9.0.post0:\n",
            "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 6.0.1\n",
            "    Uninstalling plotly-6.0.1:\n",
            "      Successfully uninstalled plotly-6.0.1\n",
            "  Attempting uninstall: contourpy\n",
            "    Found existing installation: contourpy 1.3.1\n",
            "    Uninstalling contourpy-1.3.1:\n",
            "      Successfully uninstalled contourpy-1.3.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.3\n",
            "    Uninstalling pandas-2.2.3:\n",
            "      Successfully uninstalled pandas-2.2.3\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.1\n",
            "    Uninstalling matplotlib-3.10.1:\n",
            "      Successfully uninstalled matplotlib-3.10.1\n",
            "  Attempting uninstall: catboost\n",
            "    Found existing installation: catboost 1.2.7\n",
            "    Uninstalling catboost-1.2.7:\n",
            "      Successfully uninstalled catboost-1.2.7\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed catboost-1.2.7 contourpy-1.3.1 cycler-0.12.1 fonttools-4.56.0 graphviz-0.20.3 kiwisolver-1.4.8 matplotlib-3.10.1 narwhals-1.31.0 numpy-1.26.4 packaging-24.2 pandas-2.2.3 pillow-11.1.0 plotly-6.0.1 pyparsing-3.2.1 python-dateutil-2.9.0.post0 pytz-2025.1 scipy-1.15.2 six-1.17.0 tzdata-2025.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "cycler",
                  "dateutil",
                  "kiwisolver",
                  "six"
                ]
              },
              "id": "7bf1f9314cd3425cacc0816c706ab9bf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#37. Implement a CatBoost Classifier and compute accuracy.\n",
        "\n",
        "\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create CatBoost Classifier\n",
        "catboost_clf = CatBoostClassifier(n_estimators=100, learning_rate=0.1, verbose=0, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "catboost_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = catboost_clf.predict(X_test)\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"CatBoost Classifier Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "7oBFInK_Xh1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e25d8f1c-4966-4398-9c2d-78cd3be3812a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CatBoost Classifier Accuracy: 0.9649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "urXYEQJEXhzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#38 38. Implement a Voting Classifier using Logistic Regression, Decision Tree, and SVM, and compute accuracy.\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define base models\n",
        "log_clf = LogisticRegression(max_iter=1000, random_state=42)\n",
        "tree_clf = DecisionTreeClassifier(random_state=42)\n",
        "svm_clf = SVC(probability=True, random_state=42)\n",
        "\n",
        "# Create Voting Classifier\n",
        "voting_clf = VotingClassifier(estimators=[\n",
        "    ('Logistic Regression', log_clf),\n",
        "    ('Decision Tree', tree_clf),\n",
        "    ('SVM', svm_clf)\n",
        "], voting='soft')\n",
        "\n",
        "# Train the Voting Classifier\n",
        "voting_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = voting_clf.predict(X_test)\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Voting Classifier Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "-GkIWc9dXhwf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "187b909a-9193-4949-969d-51c66c6bf75a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Voting Classifier Accuracy: 0.9737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I790QPxyXhuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#. Implement a Bagging Classifier using Decision Tree and compute accuracy.\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create Bagging Classifier with Decision Tree\n",
        "# Replace 'base_estimator' with 'estimator'\n",
        "bagging_clf = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(random_state=42),\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "bagging_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = bagging_clf.predict(X_test)\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Bagging Classifier Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "u3RNI44yXhrk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fec4d317-e183-414e-a019-1a94ee961fa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier Accuracy: 0.9561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#41. Implement a AdaBoost Classifier using Decision Tree and compute accuracy.\n",
        "\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create AdaBoost Classifier with Decision Tree as base estimator\n",
        "# Changed 'base_estimator' to 'estimator'\n",
        "adaboost_clf = AdaBoostClassifier(\n",
        "    estimator=DecisionTreeClassifier(max_depth=1, random_state=42),\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "adaboost_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = adaboost_clf.predict(X_test)\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"AdaBoost Classifier Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "oiuvozAqXhpI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9339f99f-b541-4541-8657-0811876ae767"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoost Classifier Accuracy: 0.9561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Marr4hsnXhmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#42 Train a Bagging Classifier and evaluate its performance using cross-validatio\n",
        "\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split the data (not strictly necessary for cross-validation, but useful for general testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Bagging Classifier with Decision Tree as base estimator\n",
        "bagging_clf = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_val_score(bagging_clf, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "# Print results\n",
        "print(f'Cross-validation scores: {cv_scores}')\n",
        "print(f'Mean accuracy: {np.mean(cv_scores):.4f}')\n"
      ],
      "metadata": {
        "id": "jnd5zOIeXhj9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ac20264-eb45-4644-fa10-eb88a479eaad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.96666667 0.96666667 0.93333333 0.96666667 1.        ]\n",
            "Mean accuracy: 0.9667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jd5GuZxnXhhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "piBkzmqIXhff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#43Train a Random Forest Classifier and plot the Precision-Recall curv T\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "from sklearn.datasets import load_iris\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split the data (not strictly necessary for cross-validation, but useful for general testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Bagging Classifier with Decision Tree as base estimator\n",
        "bagging_clf = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_val_score(bagging_clf, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "# Print results\n",
        "print(f'Cross-validation scores: {cv_scores}')\n",
        "print(f'Mean accuracy: {np.mean(cv_scores):.4f}')\n",
        "\n",
        "# Train a Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Get predicted probabilities for Precision-Recall Curve\n",
        "y_scores = rf_clf.predict_proba(X_test)\n",
        "precision = dict()\n",
        "recall = dict()\n",
        "pr_auc = dict()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "for i in range(len(data.target_names)):\n",
        "    precision[i], recall[i], _ = precision_recall_curve((y_test == i).astype(int), y_scores[:, i])\n",
        "    pr_auc[i] = auc(recall[i], precision[i])\n",
        "    plt.plot(recall[i], precision[i], label=f'Class {data.target_names[i]} (AUC = {pr_auc[i]:.2f})')\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve for Random Forest Classifier')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HburwB1RXhdU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "outputId": "63fbea1a-8b0f-48de-ac3c-40c7827de458"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.96666667 0.96666667 0.93333333 0.96666667 1.        ]\n",
            "Mean accuracy: 0.9667\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2pbgbFkvXhbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#44 Train a Random Forest Classifier and plot the Precision-Recall curv T\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, StackingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.metrics import precision_recall_curve, auc, accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split the data\n",
        "test_size = 0.2\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
        "\n",
        "# Create a Bagging Classifier with Decision Tree as base estimator\n",
        "bagging_clf = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_val_score(bagging_clf, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "# Print results\n",
        "print(f'Cross-validation scores: {cv_scores}')\n",
        "print(f'Mean accuracy: {np.mean(cv_scores):.4f}')\n",
        "\n",
        "# Train a Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Get predicted probabilities for Precision-Recall Curve\n",
        "y_scores = rf_clf.predict_proba(X_test)\n",
        "precision = dict()\n",
        "recall = dict()\n",
        "pr_auc = dict()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "for i in range(len(data.target_names)):\n",
        "    precision[i], recall[i], _ = precision_recall_curve((y_test == i).astype(int), y_scores[:, i])\n",
        "    pr_auc[i] = auc(recall[i], precision[i])\n",
        "    plt.plot(recall[i], precision[i], label=f'Class {data.target_names[i]} (AUC = {pr_auc[i]:.2f})')\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve for Random Forest Classifier')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Train a Stacking Classifier with Random Forest and Logistic Regression\n",
        "estimators = [('rf', RandomForestClassifier(n_estimators=50, random_state=42)),\n",
        "              ('lr', LogisticRegression(max_iter=1000))]\n",
        "stacking_clf = StackingClassifier(estimators=estimators, final_estimator=SVC(probability=True))\n",
        "stacking_clf.fit(X_train, y_train)\n",
        "y_pred = stacking_clf.predict(X_test)\n",
        "\n",
        "# Evaluate Stacking Classifier\n",
        "stacking_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Stacking Classifier Accuracy: {stacking_accuracy:.4f}')\n"
      ],
      "metadata": {
        "id": "BFoKkfD5XhYw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "outputId": "e8e844f4-1c5f-4ac1-d7e0-7f60ed8594ba"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.96666667 0.96666667 0.93333333 0.96666667 1.        ]\n",
            "Mean accuracy: 0.9667\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Classifier Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YyYQUbZJXhWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#45 Train a Bagging Regressor with different levels of bootstrap samples and compare performance.\n",
        "\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, StackingClassifier, BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.metrics import precision_recall_curve, auc, accuracy_score, mean_squared_error\n",
        "from sklearn.datasets import load_iris, load_diabetes\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load classification dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split the data\n",
        "test_size = 0.2\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
        "\n",
        "# Create a Bagging Classifier with Decision Tree as base estimator\n",
        "bagging_clf = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_val_score(bagging_clf, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "# Print results\n",
        "print(f'Cross-validation scores: {cv_scores}')\n",
        "print(f'Mean accuracy: {np.mean(cv_scores):.4f}')\n",
        "\n",
        "# Train a Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Get predicted probabilities for Precision-Recall Curve\n",
        "y_scores = rf_clf.predict_proba(X_test)\n",
        "precision = dict()\n",
        "recall = dict()\n",
        "pr_auc = dict()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "for i in range(len(data.target_names)):\n",
        "    precision[i], recall[i], _ = precision_recall_curve((y_test == i).astype(int), y_scores[:, i])\n",
        "    pr_auc[i] = auc(recall[i], precision[i])\n",
        "    plt.plot(recall[i], precision[i], label=f'Class {data.target_names[i]} (AUC = {pr_auc[i]:.2f})')\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve for Random Forest Classifier')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Train a Stacking Classifier with Random Forest and Logistic Regression\n",
        "estimators = [('rf', RandomForestClassifier(n_estimators=50, random_state=42)),\n",
        "              ('lr', LogisticRegression(max_iter=1000))]\n",
        "stacking_clf = StackingClassifier(estimators=estimators, final_estimator=SVC(probability=True))\n",
        "stacking_clf.fit(X_train, y_train)\n",
        "y_pred = stacking_clf.predict(X_test)\n",
        "\n",
        "# Evaluate Stacking Classifier\n",
        "stacking_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Stacking Classifier Accuracy: {stacking_accuracy:.4f}')\n",
        "\n",
        "# Load regression dataset\n",
        "diabetes = load_diabetes()\n",
        "X_reg, y_reg = diabetes.data, diabetes.target\n",
        "\n",
        "# Split the regression data\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Bagging Regressor with different levels of bootstrap samples\n",
        "for bootstrap in [True, False]:\n",
        "    bagging_reg = BaggingRegressor(base_estimator=DecisionTreeRegressor(), n_estimators=50, bootstrap=bootstrap, random_state=42)\n",
        "    bagging_reg.fit(X_train_reg, y_train_reg)\n",
        "    y_pred_reg = bagging_reg.predict(X_test_reg)\n",
        "    mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
        "    print(f'Bagging Regressor (bootstrap={bootstrap}) MSE: {mse:.4f}')\n",
        "\n"
      ],
      "metadata": {
        "id": "6lP_N0MRXhUF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 827
        },
        "outputId": "e6a9d746-caa7-4485-82ee-4852348eb2a3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.96666667 0.96666667 0.93333333 0.96666667 1.        ]\n",
            "Mean accuracy: 0.9667\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Classifier Accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'DecisionTreeRegressor' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-9ca6745b6477>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m# Train a Bagging Regressor with different levels of bootstrap samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbootstrap\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mbagging_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBaggingRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDecisionTreeRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbootstrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbootstrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mbagging_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_reg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0my_pred_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbagging_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_reg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'DecisionTreeRegressor' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3uWV2-CmXhR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fE4qHtdVXhPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OxgogL4sXhNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "igXAh6oiXhLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qn2g14CIXhJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v8lBu5oyXhGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F-y49YdoXhEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0ndWAEegXhCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fd_kyTvmXhAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S5PLvJ7rXg9o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}